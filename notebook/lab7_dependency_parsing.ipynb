{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d9b929",
   "metadata": {},
   "source": [
    "## Phần 1: Giới thiệu và Cài đặt\n",
    "\n",
    "Phân tích cú pháp phụ thuộc là một kỹ thuật nền tảng cho phép chúng ta hiểu cấu trúc ngữ pháp của câu dưới dạng các mối quan hệ **head** (điều khiển) và **dependent** (phụ thuộc). Trong bài thực hành này, chúng ta sẽ sử dụng **spaCy**, một thư viện NLP công nghiệp, để khám phá kỹ thuật này.\n",
    "\n",
    "**Cài đặt:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb99d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài đặt spaCy\n",
    "!pip install -U spacy\n",
    "\n",
    "# Tải về mô hình tiếng Anh (kích thước trung bình, có đủ thông tin cho parsing)\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13309cb1",
   "metadata": {},
   "source": [
    "## Phần 2: Phân tích câu và Trực quan hóa\n",
    "\n",
    "Trực quan hóa là cách tốt nhất để bắt đầu hiểu về cây phụ thuộc. spaCy cung cấp một công cụ tuyệt vời tên là **displaCy**.\n",
    "\n",
    "### 2.1. Tải mô hình và phân tích câu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288db808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Tải mô hình tiếng Anh đã cài đặt\n",
    "# Sử dụng en_core_web_md vì nó chứa các vector từ và cây cú pháp đầy đủ\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Câu ví dụ\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Phân tích câu với pipeline của spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "print(f\"Đã phân tích câu: {text}\")\n",
    "print(f\"Số lượng tokens: {len(doc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b98f60",
   "metadata": {},
   "source": [
    "### 2.2. Trực quan hóa cây phụ thuộc\n",
    "\n",
    "displaCy có thể hiển thị cây phụ thuộc trực tiếp trong Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dfaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị cây phụ thuộc trong notebook\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "\n",
    "# Tùy chọn: có thể tùy chỉnh hiển thị\n",
    "# options = {\"compact\": True, \"color\": \"blue\", \"font\": \"Source Sans Pro\"}\n",
    "# displacy.render(doc, style=\"dep\", jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac959e",
   "metadata": {},
   "source": [
    "### Câu hỏi:\n",
    "\n",
    "1. **Từ nào là gốc (ROOT) của câu?**\n",
    "2. **`jumps` có những từ phụ thuộc (dependent) nào? Các quan hệ đó là gì?**\n",
    "3. **`fox` là head của những từ nào?**\n",
    "\n",
    "Hãy quan sát cây phụ thuộc và trả lời các câu hỏi trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giải đáp câu hỏi bằng code\n",
    "for token in doc:\n",
    "    if token.dep_ == \"ROOT\":\n",
    "        print(f\"Câu trả lời 1: Từ gốc (ROOT) là: '{token.text}'\")\n",
    "        print(f\"\\nCâu trả lời 2: Các từ phụ thuộc của '{token.text}':\")\n",
    "        for child in token.children:\n",
    "            print(f\"  - {child.text} ({child.dep_})\")\n",
    "\n",
    "print(\"\\nCâu trả lời 3:\")\n",
    "for token in doc:\n",
    "    if token.text == \"fox\":\n",
    "        print(f\"'{token.text}' là head của:\")\n",
    "        for child in token.children:\n",
    "            print(f\"  - {child.text} ({child.dep_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10d63b",
   "metadata": {},
   "source": [
    "## Phần 3: Truy cập các thành phần trong cây phụ thuộc\n",
    "\n",
    "Trực quan hóa rất hữu ích, nhưng sức mạnh thực sự đến từ việc truy cập cây phụ thuộc theo chương trình. Mỗi **Token** trong đối tượng **Doc** của spaCy chứa đầy đủ thông tin về vị trí của nó trong cây.\n",
    "\n",
    "Hãy phân tích các thuộc tính quan trọng của một token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62648ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy một câu khác để phân tích\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# In ra thông tin của từng token\n",
    "print(f\"{'TEXT':<12} | {'DEP':<10} | {'HEAD TEXT':<12} | {'HEAD POS':<8} | {'CHILDREN'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for token in doc:\n",
    "    # Trích xuất các thuộc tính\n",
    "    children = [child.text for child in token.children]\n",
    "    \n",
    "    print(f\"{token.text:<12} | {token.dep_:<10} | {token.head.text:<12} | {token.head.pos_:<8} | {children}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc11e65",
   "metadata": {},
   "source": [
    "### Giải thích các thuộc tính:\n",
    "\n",
    "- **`token.text`**: Văn bản của token.\n",
    "- **`token.dep_`**: Nhãn quan hệ phụ thuộc của token này với head của nó.\n",
    "- **`token.head.text`**: Văn bản của token head.\n",
    "- **`token.head.pos_`**: Part-of-Speech tag của token head.\n",
    "- **`token.children`**: Một iterator chứa các token con (dependent) của token hiện tại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e2c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa câu này\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20411e7f",
   "metadata": {},
   "source": [
    "## Phần 4: Duyệt cây phụ thuộc để trích xuất thông tin\n",
    "\n",
    "Bây giờ, chúng ta sẽ sử dụng các thuộc tính đã học để giải quyết các bài toán cụ thể.\n",
    "\n",
    "### 4.1. Bài toán: Tìm chủ ngữ và tân ngữ của một động từ\n",
    "\n",
    "Chúng ta muốn tìm các cặp **(chủ ngữ, động từ, tân ngữ)** trong câu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The cat chased the mouse and the dog watched them.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"Tìm các bộ ba (subject, verb, object):\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    # Chỉ tìm các động từ\n",
    "    if token.pos_ == \"VERB\":\n",
    "        verb = token.text\n",
    "        subject = \"\"\n",
    "        obj = \"\"\n",
    "        \n",
    "        # Tìm chủ ngữ (nsubj) và tân ngữ (dobj) trong các con của động từ\n",
    "        for child in token.children:\n",
    "            if child.dep_ == \"nsubj\":\n",
    "                subject = child.text\n",
    "            if child.dep_ == \"dobj\":\n",
    "                obj = child.text\n",
    "        \n",
    "        if subject and obj:\n",
    "            print(f\"Found Triplet: ({subject}, {verb}, {obj})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa để xem cấu trúc\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cc104e",
   "metadata": {},
   "source": [
    "### 4.2. Bài toán: Tìm các tính từ bổ nghĩa cho một danh từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The big, fluffy white cat is sleeping on the warm mat.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"Tìm các tính từ bổ nghĩa cho danh từ:\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    # Chỉ tìm các danh từ\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        adjectives = []\n",
    "        # Tìm các tính từ bổ nghĩa (amod) trong các con của danh từ\n",
    "        for child in token.children:\n",
    "            if child.dep_ == \"amod\":\n",
    "                adjectives.append(child.text)\n",
    "        \n",
    "        if adjectives:\n",
    "            print(f\"Danh từ '{token.text}' được bổ nghĩa bởi các tính từ: {adjectives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f36e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6a5b7",
   "metadata": {},
   "source": [
    "## Phần 5: Bài tập tự luyện\n",
    "\n",
    "### Bài 1: Tìm động từ chính của câu\n",
    "\n",
    "Động từ chính của câu thường có quan hệ **ROOT**. Viết một hàm `find_main_verb(doc)` nhận vào một đối tượng **Doc** của spaCy và trả về **Token** là động từ chính."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ca0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_main_verb(doc):\n",
    "    \"\"\"\n",
    "    Tìm động từ chính (ROOT) của câu.\n",
    "    \n",
    "    Args:\n",
    "        doc: spaCy Doc object\n",
    "    \n",
    "    Returns:\n",
    "        Token: Động từ chính của câu (ROOT token)\n",
    "    \"\"\"\n",
    "    for token in doc:\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            return token\n",
    "    return None\n",
    "\n",
    "# Test hàm\n",
    "test_sentences = [\n",
    "    \"The cat sleeps on the mat.\",\n",
    "    \"Apple is looking at buying U.K. startup.\",\n",
    "    \"The students study hard for their exams.\"\n",
    "]\n",
    "\n",
    "print(\"Bài 1: Tìm động từ chính\\n\")\n",
    "for sentence in test_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    main_verb = find_main_verb(doc)\n",
    "    if main_verb:\n",
    "        print(f\"Câu: '{sentence}'\")\n",
    "        print(f\"Động từ chính: '{main_verb.text}' (POS: {main_verb.pos_})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed41f082",
   "metadata": {},
   "source": [
    "### Bài 2: Trích xuất các cụm danh từ (Noun Chunks)\n",
    "\n",
    "spaCy đã có sẵn thuộc tính `.noun_chunks` để trích xuất các cụm danh từ. Tuy nhiên, hãy thử tự viết một hàm để làm điều tương tự.\n",
    "\n",
    "**Gợi ý**: Một cụm danh từ đơn giản là một danh từ và tất cả các từ bổ nghĩa cho nó (như `det`, `amod`, `compound`). Bạn có thể bắt đầu từ một danh từ và duyệt xuống các **children** của nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca40732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_chunks(doc):\n",
    "    \"\"\"\n",
    "    Trích xuất các cụm danh từ từ câu.\n",
    "    \n",
    "    Args:\n",
    "        doc: spaCy Doc object\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh sách các cụm danh từ (mỗi cụm là một list các token text)\n",
    "    \"\"\"\n",
    "    noun_chunks = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # Tìm các danh từ\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "            chunk = []\n",
    "            \n",
    "            # Thu thập các từ bổ nghĩa (det, amod, compound) đứng trước\n",
    "            modifiers = []\n",
    "            for child in token.children:\n",
    "                if child.dep_ in [\"det\", \"amod\", \"compound\", \"nummod\"]:\n",
    "                    modifiers.append(child)\n",
    "            \n",
    "            # Sắp xếp theo thứ tự xuất hiện trong câu\n",
    "            modifiers.sort(key=lambda x: x.i)\n",
    "            \n",
    "            # Xây dựng cụm danh từ\n",
    "            for mod in modifiers:\n",
    "                chunk.append(mod.text)\n",
    "            chunk.append(token.text)\n",
    "            \n",
    "            # Thêm các từ đứng sau (prep, pobj nếu có)\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"prep\":\n",
    "                    chunk.append(child.text)\n",
    "                    for grandchild in child.children:\n",
    "                        if grandchild.dep_ == \"pobj\":\n",
    "                            chunk.append(grandchild.text)\n",
    "            \n",
    "            noun_chunks.append(chunk)\n",
    "    \n",
    "    return noun_chunks\n",
    "\n",
    "# Test hàm\n",
    "test_text = \"The big fluffy white cat is sleeping on the warm comfortable mat.\"\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"Bài 2: Trích xuất cụm danh từ\\n\")\n",
    "print(f\"Câu: '{test_text}'\\n\")\n",
    "\n",
    "# So sánh với spaCy built-in\n",
    "print(\"spaCy built-in noun chunks:\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"  - {chunk.text}\")\n",
    "\n",
    "print(\"\\nCustom function noun chunks:\")\n",
    "custom_chunks = extract_noun_chunks(doc)\n",
    "for chunk in custom_chunks:\n",
    "    print(f\"  - {' '.join(chunk)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b57660",
   "metadata": {},
   "source": [
    "### Bài 3: Tìm đường đi ngắn nhất trong cây\n",
    "\n",
    "Viết một hàm `get_path_to_root(token)` để tìm đường đi từ một token bất kỳ lên đến gốc (ROOT) của cây. Hàm nên trả về một danh sách các token trên đường đi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ef0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_to_root(token):\n",
    "    \"\"\"\n",
    "    Tìm đường đi từ token lên đến ROOT của cây.\n",
    "    \n",
    "    Args:\n",
    "        token: spaCy Token object\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh sách các token từ token ban đầu lên đến ROOT\n",
    "    \"\"\"\n",
    "    path = [token]\n",
    "    current = token\n",
    "    \n",
    "    # Duyệt lên đến khi gặp ROOT\n",
    "    while current.dep_ != \"ROOT\":\n",
    "        current = current.head\n",
    "        path.append(current)\n",
    "        \n",
    "        # Tránh vòng lặp vô hạn (nếu có lỗi trong cây)\n",
    "        if len(path) > 100:\n",
    "            break\n",
    "    \n",
    "    return path\n",
    "\n",
    "# Test hàm\n",
    "test_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"Bài 3: Tìm đường đi đến ROOT\\n\")\n",
    "print(f\"Câu: '{test_text}'\\n\")\n",
    "\n",
    "# Test với một vài token\n",
    "test_tokens = [\"brown\", \"lazy\", \"dog\"]\n",
    "\n",
    "for token_text in test_tokens:\n",
    "    for token in doc:\n",
    "        if token.text == token_text:\n",
    "            path = get_path_to_root(token)\n",
    "            path_text = \" -> \".join([t.text for t in path])\n",
    "            print(f\"Đường đi từ '{token_text}' đến ROOT:\")\n",
    "            print(f\"  {path_text}\")\n",
    "            print(f\"  (Độ dài: {len(path)} bước)\\n\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4899a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa để kiểm tra\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e8636",
   "metadata": {},
   "source": [
    "## Bài tập nâng cao\n",
    "\n",
    "### Bài 4: Tìm tất cả các mệnh đề phụ thuộc (dependent clauses)\n",
    "\n",
    "Tìm các mệnh đề phụ thuộc trong câu (thường có quan hệ `advcl`, `relcl`, `ccomp`, `xcomp`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dependent_clauses(doc):\n",
    "    \"\"\"\n",
    "    Tìm các mệnh đề phụ thuộc trong câu.\n",
    "    \n",
    "    Args:\n",
    "        doc: spaCy Doc object\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh sách các mệnh đề phụ thuộc\n",
    "    \"\"\"\n",
    "    clause_deps = [\"advcl\", \"relcl\", \"ccomp\", \"xcomp\", \"acl\"]\n",
    "    clauses = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.dep_ in clause_deps:\n",
    "            # Lấy toàn bộ subtree của mệnh đề\n",
    "            clause_tokens = list(token.subtree)\n",
    "            clause_tokens.sort(key=lambda x: x.i)\n",
    "            clause_text = \" \".join([t.text for t in clause_tokens])\n",
    "            \n",
    "            clauses.append({\n",
    "                \"type\": token.dep_,\n",
    "                \"head\": token.head.text,\n",
    "                \"text\": clause_text,\n",
    "                \"verb\": token.text\n",
    "            })\n",
    "    \n",
    "    return clauses\n",
    "\n",
    "# Test\n",
    "test_sentences = [\n",
    "    \"I know that you are smart.\",\n",
    "    \"She left after she finished her work.\",\n",
    "    \"The book that I bought is interesting.\",\n",
    "    \"He wants to learn programming.\"\n",
    "]\n",
    "\n",
    "print(\"Bài 4: Tìm mệnh đề phụ thuộc\\n\")\n",
    "for sentence in test_sentences:\n",
    "    doc = nlp(sentence)\n",
    "    clauses = find_dependent_clauses(doc)\n",
    "    \n",
    "    print(f\"Câu: '{sentence}'\")\n",
    "    if clauses:\n",
    "        for clause in clauses:\n",
    "            print(f\"  - Loại: {clause['type']}, Head: '{clause['head']}', Verb: '{clause['verb']}'\")\n",
    "            print(f\"    Mệnh đề: '{clause['text']}'\")\n",
    "    else:\n",
    "        print(\"  - Không tìm thấy mệnh đề phụ thuộc\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f1262",
   "metadata": {},
   "source": [
    "### Bài 5: Phân tích câu phức tạp\n",
    "\n",
    "Áp dụng tất cả các kỹ thuật đã học để phân tích một câu phức tạp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715dc65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Câu phức tạp để phân tích\n",
    "complex_sentence = \"\"\"The ambitious young programmer who graduated from Stanford University last year \n",
    "is currently working on developing innovative artificial intelligence solutions \n",
    "for the leading technology company in Silicon Valley.\"\"\"\n",
    "\n",
    "doc = nlp(complex_sentence)\n",
    "\n",
    "print(\"Bài 5: Phân tích câu phức tạp\\n\")\n",
    "print(f\"Câu: {complex_sentence}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Động từ chính\n",
    "main_verb = find_main_verb(doc)\n",
    "print(f\"\\n1. Động từ chính: '{main_verb.text}'\")\n",
    "\n",
    "# 2. Chủ ngữ chính\n",
    "subject = None\n",
    "for child in main_verb.children:\n",
    "    if child.dep_ == \"nsubj\":\n",
    "        subject = child\n",
    "        break\n",
    "if subject:\n",
    "    print(f\"\\n2. Chủ ngữ chính: '{subject.text}'\")\n",
    "    print(f\"   Các từ bổ nghĩa cho chủ ngữ:\")\n",
    "    for child in subject.children:\n",
    "        print(f\"   - {child.text} ({child.dep_})\")\n",
    "\n",
    "# 3. Cụm danh từ\n",
    "print(f\"\\n3. Các cụm danh từ:\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(f\"   - {chunk.text}\")\n",
    "\n",
    "# 4. Mệnh đề phụ thuộc\n",
    "clauses = find_dependent_clauses(doc)\n",
    "print(f\"\\n4. Mệnh đề phụ thuộc:\")\n",
    "if clauses:\n",
    "    for clause in clauses:\n",
    "        print(f\"   - {clause['type']}: {clause['text']}\")\n",
    "else:\n",
    "    print(\"   - Không có mệnh đề phụ thuộc\")\n",
    "\n",
    "# 5. Các giới từ và cụm giới từ\n",
    "print(f\"\\n5. Các cụm giới từ:\")\n",
    "for token in doc:\n",
    "    if token.pos_ == \"ADP\":\n",
    "        prep_phrase = [token.text]\n",
    "        for child in token.children:\n",
    "            if child.dep_ == \"pobj\":\n",
    "                prep_phrase.append(child.text)\n",
    "                # Thêm các modifier của object\n",
    "                for grandchild in child.children:\n",
    "                    if grandchild.dep_ in [\"det\", \"amod\", \"compound\"]:\n",
    "                        prep_phrase.insert(-1, grandchild.text)\n",
    "        print(f\"   - {' '.join(prep_phrase)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba12056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trực quan hóa câu phức tạp\n",
    "displacy.render(doc, style=\"dep\", jupyter=True, options={\"compact\": True, \"distance\": 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af2256",
   "metadata": {},
   "source": [
    "### Tài liệu tham khảo:\n",
    "\n",
    "- [spaCy Documentation](https://spacy.io/usage/linguistic-features#dependency-parse)\n",
    "- [Universal Dependencies](https://universaldependencies.org/)\n",
    "- [Dependency Relations](https://universaldependencies.org/u/dep/index.html)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
